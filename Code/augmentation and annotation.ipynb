{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '\\\\*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            try:\n",
    "                value = (root.find('filename').text,\n",
    "                         int(root.find('size')[0].text),\n",
    "                         int(root.find('size')[1].text),\n",
    "                         member[0].text,\n",
    "                         int(member[4][0].text),\n",
    "                         int(member[4][1].text),\n",
    "                         int(member[4][2].text),\n",
    "                         int(member[4][3].text)\n",
    "                         )\n",
    "                xml_list.append(value)\n",
    "            except:\n",
    "                pass\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_passport_labels_df = xml_to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\uk_passport')\n",
    "uk_passport_labels_df.to_csv(('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\uk_passport_labels.csv'), index=None)\n",
    "\n",
    "singapore_passport_labels_df = xml_to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\singapore_passport')\n",
    "singapore_passport_labels_df.to_csv(('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\singapore_passport_labels.csv'), index=None)\n",
    "\n",
    "pakistan_passport_labels_df = xml_to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\pakistani_passport')\n",
    "pakistan_passport_labels_df.to_csv(('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\pakistan_passport_labels.csv'), index=None)\n",
    "\n",
    "pakistan_cnic_labels_df = xml_to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\pakistani_cnic')\n",
    "pakistan_cnic_labels_df.to_csv(('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\pakistan_cnic_labels.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbs_obj_to_df(bbs_object):\n",
    "    bbs_array = bbs_object.to_xyxy_array()\n",
    "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    return df_bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgaug(df, images_path, aug_images_path, image_prefix):\n",
    "    aug_bbs_xy = pd.DataFrame(columns=['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    grouped = df.groupby('filename')    \n",
    "    \n",
    "    for filename in df['filename'].unique():\n",
    "        group_df = grouped.get_group(filename)\n",
    "        group_df = group_df.reset_index()\n",
    "        group_df = group_df.drop(['index'], axis=1)\n",
    "\n",
    "        if group_df['height'].unique()[0] >= group_df['width'].unique()[0] and group_df['height'].unique()[0] > 600:\n",
    "            image = imageio.imread(images_path+filename)   \n",
    "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "            image_aug, bbs_aug = height_resize(image=image, bounding_boxes=bbs)\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
    "\n",
    "        elif group_df['width'].unique()[0] > group_df['height'].unique()[0] and group_df['width'].unique()[0] > 600:\n",
    "            image = imageio.imread(images_path+filename)     \n",
    "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "            image_aug, bbs_aug = width_resize(image=image, bounding_boxes=bbs)\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
    "        else:\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, group_df])\n",
    "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
    "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
    "    return aug_bbs_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakistan_CNIC_resized_images_df = resize_imgaug(pakistan_cnic_labels_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_CNIC\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_CNIC\\\\', '')\n",
    "pakistan_passport_resized_images_df = resize_imgaug(pakistan_passport_labels_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_Passport\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_Passport\\\\', '')\n",
    "singapore_passport_resized_images_df = resize_imgaug(singapore_passport_labels_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\singapore_passport\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\singapore_passport\\\\', '')\n",
    "uk_passport_resized_images_df = resize_imgaug(uk_passport_labels_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\uk_passport\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\uk_passport\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.SomeOf(2, [    \n",
    "    iaa.Affine(scale=(0.5, 1.5)),\n",
    "    iaa.Affine(rotate=(-60, 60)),\n",
    "    iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n",
    "    iaa.Fliplr(1),\n",
    "    iaa.Multiply((0.5, 1.5)),\n",
    "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
    "    aug_bbs_xy = pd.DataFrame(columns=['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    grouped = df.groupby('filename')\n",
    "    for filename in df['filename'].unique():\n",
    "        group_df = grouped.get_group(filename)\n",
    "        group_df = group_df.reset_index()\n",
    "        group_df = group_df.drop(['index'], axis=1)   \n",
    "        image = imageio.imread(images_path+filename)       \n",
    "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
    "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
    "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs) \n",
    "        bbs_aug = bbs_aug.remove_out_of_image()\n",
    "        bbs_aug = bbs_aug.clip_out_of_image()\n",
    "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
    "            pass\n",
    "        else:\n",
    "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
    "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
    "            for index, _ in info_df.iterrows():\n",
    "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
    "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
    "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
    "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
    "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
    "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
    "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
    "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
    "    return aug_bbs_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 100):\n",
    "    p_cnic_df = image_aug(pakistan_CNIC_resized_images_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_CNIC\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\p_cnic\\\\', 'aug'+str(i)+'_', aug)\n",
    "    p_cnic_augmented_images_df = augmented_images_df.append(p_cnic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 100):\n",
    "    p_pass_df = image_aug(pakistan_passport_resized_images_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_Passport\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\p_pass\\\\', 'aug'+str(i)+'_', aug)\n",
    "    p_pass_augmented_images_df = augmented_images_df.append(p_pass_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 100):\n",
    "    u_pass_df = image_aug(uk_passport_resized_images_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\uk_passport\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\u_pass\\\\', 'aug'+str(i)+'_', aug)\n",
    "    u_pass_augmented_images_df = augmented_images_df.append(u_pass_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 100):\n",
    "    s_pass_df = image_aug(singapore_passport_resized_images_df, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\singapore_passport\\\\', 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\s_pass\\\\', 'aug'+str(i)+'_', aug)\n",
    "    s_pass_augmented_images_df = augmented_images_df.append(s_pass_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_df = pd.concat([uk_passport_resized_images_df, u_pass_augmented_images_df])\n",
    "all_labels_df.to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\all_labels_uk_passport.csv', index=False)\n",
    "\n",
    "all_labels_df = pd.concat([singapore_passport_resized_images_df, s_pass_augmented_images_df])\n",
    "all_labels_df.to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\all_labels_singapore_passport.csv', index=False)\n",
    "\n",
    "all_labels_df = pd.concat([pakistan_passport_resized_images_df, p_pass_augmented_images_df])\n",
    "all_labels_df.to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\all_labels_pakistan_passport.csv', index=False)\n",
    "\n",
    "all_labels_df = pd.concat([pakistan_CNIC_resized_images_df, p_cnic_augmented_images_df])\n",
    "all_labels_df.to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\labels\\\\all_labels_pakistan_cnic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\s_pass'):\n",
    "    shutil.copy('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\s_pass\\\\'+file, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_CNIC\\\\'+file)\n",
    "for file in os.listdir('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\u_pass'):\n",
    "    shutil.copy('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\u_pass\\\\'+file, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\Pakistani_Passport\\\\'+file)\n",
    "for file in os.listdir('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\p_pass'):\n",
    "    shutil.copy('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\p_pass\\\\'+file, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\uk_passport\\\\'+file)\n",
    "for file in os.listdir('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\p_cnic\\\\'):\n",
    "    shutil.copy('C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\p_cnic\\\\'+file, 'C:\\\\Users\\\\HP\\\\Desktop\\\\DS_Project_Dataset\\\\singapore_passport\\\\'+file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
